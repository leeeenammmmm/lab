{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c870500",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T07:36:25.986044Z",
     "iopub.status.busy": "2023-08-14T07:36:25.985634Z",
     "iopub.status.idle": "2023-08-14T07:36:40.465358Z",
     "shell.execute_reply": "2023-08-14T07:36:40.464232Z"
    },
    "papermill": {
     "duration": 14.495944,
     "end_time": "2023-08-14T07:36:40.467769",
     "exception": false,
     "start_time": "2023-08-14T07:36:25.971825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.30.2)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.1)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23dad3e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T07:36:40.482659Z",
     "iopub.status.busy": "2023-08-14T07:36:40.482355Z",
     "iopub.status.idle": "2023-08-14T07:36:51.276479Z",
     "shell.execute_reply": "2023-08-14T07:36:51.275518Z"
    },
    "papermill": {
     "duration": 10.80413,
     "end_time": "2023-08-14T07:36:51.278815",
     "exception": false,
     "start_time": "2023-08-14T07:36:40.474685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from scipy.stats import chi2\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7889acc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T07:36:51.293494Z",
     "iopub.status.busy": "2023-08-14T07:36:51.292965Z",
     "iopub.status.idle": "2023-08-14T07:36:51.389774Z",
     "shell.execute_reply": "2023-08-14T07:36:51.388219Z"
    },
    "papermill": {
     "duration": 0.106302,
     "end_time": "2023-08-14T07:36:51.391768",
     "exception": false,
     "start_time": "2023-08-14T07:36:51.285466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56f53ea6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T07:36:51.406306Z",
     "iopub.status.busy": "2023-08-14T07:36:51.405901Z",
     "iopub.status.idle": "2023-08-14T07:36:51.410849Z",
     "shell.execute_reply": "2023-08-14T07:36:51.409915Z"
    },
    "papermill": {
     "duration": 0.014442,
     "end_time": "2023-08-14T07:36:51.412829",
     "exception": false,
     "start_time": "2023-08-14T07:36:51.398387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"num_labels\": 7,\n",
    "    \"hidden_dropout_prob\": 0.15,\n",
    "    \"hidden_size\": 768,\n",
    "    \"max_length\": 512,\n",
    "}\n",
    "\n",
    "training_parameters = {\n",
    "    \"batch_size\": 2,\n",
    "    \"epochs\": 1,\n",
    "    \"output_folder\": \"/kaggle/working\",\n",
    "    \"output_file\": \"model.bin\",\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"print_after_steps\": 100,\n",
    "    \"save_steps\": 5000,\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df41097a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T07:36:51.428040Z",
     "iopub.status.busy": "2023-08-14T07:36:51.427775Z",
     "iopub.status.idle": "2023-08-14T07:37:11.875867Z",
     "shell.execute_reply": "2023-08-14T07:37:11.874879Z"
    },
    "papermill": {
     "duration": 20.457906,
     "end_time": "2023-08-14T07:37:11.878200",
     "exception": false,
     "start_time": "2023-08-14T07:36:51.420294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fb94101eaad4010b968314b39c4b6bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/467 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94243ae49bed433e90d1f2f2ae1f6301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/336M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at jackaduma/SecBERT were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained('jackaduma/SecBERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8a01191",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T07:37:11.894136Z",
     "iopub.status.busy": "2023-08-14T07:37:11.893818Z",
     "iopub.status.idle": "2023-08-14T07:37:12.498567Z",
     "shell.execute_reply": "2023-08-14T07:37:12.497538Z"
    },
    "papermill": {
     "duration": 0.615414,
     "end_time": "2023-08-14T07:37:12.501046",
     "exception": false,
     "start_time": "2023-08-14T07:37:11.885632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76963a26d91f4edaa2c5b54fe4e5989f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)solve/main/vocab.txt:   0%|          | 0.00/378k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('jackaduma/SecBERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "689ef8f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T07:37:12.517704Z",
     "iopub.status.busy": "2023-08-14T07:37:12.517393Z",
     "iopub.status.idle": "2023-08-14T07:37:12.528850Z",
     "shell.execute_reply": "2023-08-14T07:37:12.527913Z"
    },
    "papermill": {
     "duration": 0.022244,
     "end_time": "2023-08-14T07:37:12.530808",
     "exception": false,
     "start_time": "2023-08-14T07:37:12.508564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from transformers import BertTokenizer, BertModel\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('jackaduma/SecBERT')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        review = self.df.iloc[index][\"text\"]\n",
    "        sentiment = self.df.iloc[index][\"label\"]\n",
    "        sentiment_dict = {'000 - Normal': 0,\n",
    "          '126 - Path Traversal': 1,\n",
    "          '242 - Code Injection': 2,\n",
    "          '153 - Input Data Manipulation': 3,\n",
    "          '310 - Scanning for Vulnerable Software': 4,\n",
    "          '194 - Fake the Source of Data': 5,\n",
    "          '34 - HTTP Response Splitting': 6}\n",
    "        label = sentiment_dict[sentiment]\n",
    "        encoded_input = self.tokenizer.encode_plus(\n",
    "                review,\n",
    "                add_special_tokens=True,\n",
    "                max_length= config[\"max_length\"],\n",
    "                pad_to_max_length=True,\n",
    "                return_overflowing_tokens=True,\n",
    "            )\n",
    "        if \"num_truncated_tokens\" in encoded_input and encoded_input[\"num_truncated_tokens\"] > 0:\n",
    "            # print(\"Attention! you are cropping tokens\")\n",
    "            pass\n",
    "\n",
    "        input_ids = encoded_input[\"input_ids\"]\n",
    "        attention_mask = encoded_input[\"attention_mask\"] if \"attention_mask\" in encoded_input else None\n",
    "\n",
    "        token_type_ids = encoded_input[\"token_type_ids\"] if \"token_type_ids\" in encoded_input else None\n",
    "\n",
    "\n",
    "\n",
    "        data_input = {\n",
    "            \"input_ids\": torch.tensor(input_ids),\n",
    "            \"attention_mask\": torch.tensor(attention_mask),\n",
    "            \"token_type_ids\": torch.tensor(token_type_ids),\n",
    "            \"label\": torch.tensor(label),\n",
    "        }\n",
    "\n",
    "        return data_input[\"input_ids\"], data_input[\"attention_mask\"], data_input[\"token_type_ids\"], data_input[\"label\"]\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "580ac01b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T07:37:12.546445Z",
     "iopub.status.busy": "2023-08-14T07:37:12.546165Z",
     "iopub.status.idle": "2023-08-14T07:37:14.150542Z",
     "shell.execute_reply": "2023-08-14T07:37:14.149516Z"
    },
    "papermill": {
     "duration": 1.614469,
     "end_time": "2023-08-14T07:37:14.152605",
     "exception": false,
     "start_time": "2023-08-14T07:37:12.538136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GET /blog/index.php/2020/04/04/voluptatum-repr...</td>\n",
       "      <td>000 - Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GET /blog/xmlrpc.php?rsd</td>\n",
       "      <td>000 - Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GET /blog/index.php/2020/04/04/nihil-tenetur-e...</td>\n",
       "      <td>000 - Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GET /blog/index.php/2020/04/04/explicabo-qui-f...</td>\n",
       "      <td>000 - Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GET /blog/index.php/2020/04/04/explicabo-qui-f...</td>\n",
       "      <td>000 - Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text         label\n",
       "0  GET /blog/index.php/2020/04/04/voluptatum-repr...  000 - Normal\n",
       "1                           GET /blog/xmlrpc.php?rsd  000 - Normal\n",
       "2  GET /blog/index.php/2020/04/04/nihil-tenetur-e...  000 - Normal\n",
       "3  GET /blog/index.php/2020/04/04/explicabo-qui-f...  000 - Normal\n",
       "4  GET /blog/index.php/2020/04/04/explicabo-qui-f...  000 - Normal"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('/kaggle/input/code-injection/dataset_capec_combine.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a836966d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T07:37:14.171049Z",
     "iopub.status.busy": "2023-08-14T07:37:14.170505Z",
     "iopub.status.idle": "2023-08-14T07:37:14.621970Z",
     "shell.execute_reply": "2023-08-14T07:37:14.620966Z"
    },
    "papermill": {
     "duration": 0.464244,
     "end_time": "2023-08-14T07:37:14.624379",
     "exception": false,
     "start_time": "2023-08-14T07:37:14.160135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GET  blog index.php 2020 04 04 voluptatum-repr...</td>\n",
       "      <td>000 - Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GET  blog xmlrpc.php?rsd</td>\n",
       "      <td>000 - Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GET  blog index.php 2020 04 04 nihil-tenetur-e...</td>\n",
       "      <td>000 - Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GET  blog index.php 2020 04 04 explicabo-qui-f...</td>\n",
       "      <td>000 - Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GET  blog index.php 2020 04 04 explicabo-qui-f...</td>\n",
       "      <td>000 - Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text         label\n",
       "0  GET  blog index.php 2020 04 04 voluptatum-repr...  000 - Normal\n",
       "1                           GET  blog xmlrpc.php?rsd  000 - Normal\n",
       "2  GET  blog index.php 2020 04 04 nihil-tenetur-e...  000 - Normal\n",
       "3  GET  blog index.php 2020 04 04 explicabo-qui-f...  000 - Normal\n",
       "4  GET  blog index.php 2020 04 04 explicabo-qui-f...  000 - Normal"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optional (not effect very much)\n",
    "df_train['text'] = df_train['text'].str.replace('/',' ')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe311c44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T07:37:14.641713Z",
     "iopub.status.busy": "2023-08-14T07:37:14.641384Z",
     "iopub.status.idle": "2023-08-14T07:37:15.156812Z",
     "shell.execute_reply": "2023-08-14T07:37:15.155803Z"
    },
    "papermill": {
     "duration": 0.526718,
     "end_time": "2023-08-14T07:37:15.159393",
     "exception": false,
     "start_time": "2023-08-14T07:37:14.632675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Reduce data for testing\n",
    "df_242 = df_train[(df_train['label'] == '242 - Code Injection')]\n",
    "df_242 = df_242.sample(frac = 1)\n",
    "df_242 = df_242[:50000]\n",
    "df_000 = df_train[(df_train['label'] == '000 - Normal')]\n",
    "df_000 = df_000.sample(frac = 1)\n",
    "df_000 = df_000[:50000]\n",
    "\n",
    "df_sub = df_train[(df_train['label'] != '000 - Normal') & (df_train['label'] != '242 - Code Injection')]\n",
    "\n",
    "df_train = pd.concat([df_train,df_242,df_000], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7e41abb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T07:37:15.177751Z",
     "iopub.status.busy": "2023-08-14T07:37:15.176150Z",
     "iopub.status.idle": "2023-08-14T07:37:15.453385Z",
     "shell.execute_reply": "2023-08-14T07:37:15.452333Z"
    },
    "papermill": {
     "duration": 0.288501,
     "end_time": "2023-08-14T07:37:15.455859",
     "exception": false,
     "start_time": "2023-08-14T07:37:15.167358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## prep\n",
    "source_dataset = ReviewDataset(df_train)\n",
    "source_dataloader = DataLoader(dataset = source_dataset, batch_size = training_parameters[\"batch_size\"], shuffle = True, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a088f692",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T07:37:15.472968Z",
     "iopub.status.busy": "2023-08-14T07:37:15.472658Z",
     "iopub.status.idle": "2023-08-14T07:37:15.542553Z",
     "shell.execute_reply": "2023-08-14T07:37:15.541348Z"
    },
    "papermill": {
     "duration": 0.081453,
     "end_time": "2023-08-14T07:37:15.545433",
     "exception": false,
     "start_time": "2023-08-14T07:37:15.463980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POST /vendor/phpunit/phpunit/src/Util/PHP/eval...</td>\n",
       "      <td>153 - Input Data Manipulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POST /cgi-bin/ViewLog.asp  remote_submit_Flag=...</td>\n",
       "      <td>153 - Input Data Manipulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GET /.svn/wc.db</td>\n",
       "      <td>153 - Input Data Manipulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GET /blog/.svn/wc.db</td>\n",
       "      <td>153 - Input Data Manipulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GET /blog/index.php/my-account/.svn/wc.db</td>\n",
       "      <td>153 - Input Data Manipulation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  POST /vendor/phpunit/phpunit/src/Util/PHP/eval...   \n",
       "1  POST /cgi-bin/ViewLog.asp  remote_submit_Flag=...   \n",
       "2                                    GET /.svn/wc.db   \n",
       "3                               GET /blog/.svn/wc.db   \n",
       "4          GET /blog/index.php/my-account/.svn/wc.db   \n",
       "\n",
       "                           label  \n",
       "0  153 - Input Data Manipulation  \n",
       "1  153 - Input Data Manipulation  \n",
       "2  153 - Input Data Manipulation  \n",
       "3  153 - Input Data Manipulation  \n",
       "4  153 - Input Data Manipulation  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transfer = pd.read_csv('/kaggle/input/code-injection/dataset_capec_transfer.csv')\n",
    "df_transfer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7718d0fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T07:37:15.563409Z",
     "iopub.status.busy": "2023-08-14T07:37:15.563121Z",
     "iopub.status.idle": "2023-08-14T07:37:15.583452Z",
     "shell.execute_reply": "2023-08-14T07:37:15.582296Z"
    },
    "papermill": {
     "duration": 0.032018,
     "end_time": "2023-08-14T07:37:15.586151",
     "exception": false,
     "start_time": "2023-08-14T07:37:15.554133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POST  vendor phpunit phpunit src Util PHP eval...</td>\n",
       "      <td>153 - Input Data Manipulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POST  cgi-bin ViewLog.asp  remote_submit_Flag=...</td>\n",
       "      <td>153 - Input Data Manipulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GET  .svn wc.db</td>\n",
       "      <td>153 - Input Data Manipulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GET  blog .svn wc.db</td>\n",
       "      <td>153 - Input Data Manipulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GET  blog index.php my-account .svn wc.db</td>\n",
       "      <td>153 - Input Data Manipulation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  POST  vendor phpunit phpunit src Util PHP eval...   \n",
       "1  POST  cgi-bin ViewLog.asp  remote_submit_Flag=...   \n",
       "2                                    GET  .svn wc.db   \n",
       "3                               GET  blog .svn wc.db   \n",
       "4          GET  blog index.php my-account .svn wc.db   \n",
       "\n",
       "                           label  \n",
       "0  153 - Input Data Manipulation  \n",
       "1  153 - Input Data Manipulation  \n",
       "2  153 - Input Data Manipulation  \n",
       "3  153 - Input Data Manipulation  \n",
       "4  153 - Input Data Manipulation  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optional (not effect very much)\n",
    "df_transfer['text'] = df_transfer['text'].str.replace('/',' ')\n",
    "df_transfer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9556f558",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T07:37:15.604529Z",
     "iopub.status.busy": "2023-08-14T07:37:15.604236Z",
     "iopub.status.idle": "2023-08-14T07:37:15.890246Z",
     "shell.execute_reply": "2023-08-14T07:37:15.889272Z"
    },
    "papermill": {
     "duration": 0.297534,
     "end_time": "2023-08-14T07:37:15.892687",
     "exception": false,
     "start_time": "2023-08-14T07:37:15.595153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_dataset = ReviewDataset(df_transfer)\n",
    "target_dataloader = DataLoader(dataset = target_dataset, batch_size = training_parameters[\"batch_size\"], shuffle = True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abe4f4e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T07:37:15.910326Z",
     "iopub.status.busy": "2023-08-14T07:37:15.909959Z",
     "iopub.status.idle": "2023-08-14T07:37:15.916964Z",
     "shell.execute_reply": "2023-08-14T07:37:15.916109Z"
    },
    "papermill": {
     "duration": 0.018346,
     "end_time": "2023-08-14T07:37:15.919193",
     "exception": false,
     "start_time": "2023-08-14T07:37:15.900847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "\n",
    "\n",
    "class GradientReversalFn(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        ctx.alpha = alpha\n",
    "        \n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output = grad_output.neg() * ctx.alpha\n",
    "\n",
    "        return output, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26b6d41e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T07:37:15.936495Z",
     "iopub.status.busy": "2023-08-14T07:37:15.936230Z",
     "iopub.status.idle": "2023-08-14T07:37:15.949193Z",
     "shell.execute_reply": "2023-08-14T07:37:15.948353Z"
    },
    "papermill": {
     "duration": 0.024602,
     "end_time": "2023-08-14T07:37:15.951846",
     "exception": false,
     "start_time": "2023-08-14T07:37:15.927244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class DomainAdaptationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DomainAdaptationModel, self).__init__()\n",
    "        \n",
    "        num_labels = config[\"num_labels\"]\n",
    "        self.bert = AutoModel.from_pretrained('jackaduma/SecBERT')\n",
    "        self.dropout = nn.Dropout(config[\"hidden_dropout_prob\"])\n",
    "        self.sentiment_classifier = nn.Sequential(\n",
    "            nn.Linear(config[\"hidden_size\"], num_labels),\n",
    "            nn.LogSoftmax(dim=1),\n",
    "        )\n",
    "        self.domain_classifier = nn.Sequential(\n",
    "            nn.Linear(config[\"hidden_size\"], 2),\n",
    "            nn.LogSoftmax(dim=1),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(\n",
    "          self,\n",
    "          input_ids=None,\n",
    "          attention_mask=None,\n",
    "          token_type_ids=None,\n",
    "          labels=None,\n",
    "          grl_lambda = 1.0, \n",
    "          ):\n",
    "\n",
    "        outputs = self.bert(\n",
    "                input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids,\n",
    "            )\n",
    "\n",
    "#         pooled_output = outputs[1] # For bert-base-uncase\n",
    "        pooled_output = outputs.pooler_output \n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "\n",
    "\n",
    "        reversed_pooled_output = GradientReversalFn.apply(pooled_output, grl_lambda)\n",
    "\n",
    "        sentiment_pred = self.sentiment_classifier(pooled_output)\n",
    "        domain_pred = self.domain_classifier(reversed_pooled_output)\n",
    "\n",
    "        return sentiment_pred.to(device), domain_pred.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "140f9ff7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T07:37:15.978284Z",
     "iopub.status.busy": "2023-08-14T07:37:15.977974Z",
     "iopub.status.idle": "2023-08-14T07:37:15.986914Z",
     "shell.execute_reply": "2023-08-14T07:37:15.985903Z"
    },
    "papermill": {
     "duration": 0.026588,
     "end_time": "2023-08-14T07:37:15.990007",
     "exception": false,
     "start_time": "2023-08-14T07:37:15.963419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(logits, labels):\n",
    "    \n",
    "    predicted_labels_dict = {\n",
    "      0: 0,\n",
    "      1: 0,\n",
    "      2: 0,\n",
    "      3: 0,\n",
    "      4: 0,\n",
    "      5: 0,\n",
    "      6: 0,\n",
    "    }\n",
    "    \n",
    "    predicted_label = logits.max(dim = 1)[1]\n",
    "    \n",
    "    for pred in predicted_label:\n",
    "        # print(pred.item())\n",
    "        predicted_labels_dict[pred.item()] += 1\n",
    "    acc = (predicted_label == labels).float().mean()\n",
    "    \n",
    "    return acc, predicted_labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca137c45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T07:37:16.022834Z",
     "iopub.status.busy": "2023-08-14T07:37:16.022427Z",
     "iopub.status.idle": "2023-08-14T07:37:16.429325Z",
     "shell.execute_reply": "2023-08-14T07:37:16.428364Z"
    },
    "papermill": {
     "duration": 0.424145,
     "end_time": "2023-08-14T07:37:16.431661",
     "exception": false,
     "start_time": "2023-08-14T07:37:16.007516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report,accuracy_score, f1_score\n",
    "def evaluate(model, dataset = \"imdb\", percentage = 5):\n",
    "    with torch.no_grad():\n",
    "        predicted_labels_dict = {                                                   \n",
    "          0: 0,\n",
    "          1: 0,\n",
    "          2: 0,\n",
    "          3: 0,\n",
    "          4: 0,\n",
    "          5: 0,\n",
    "          6: 0,                                                                   \n",
    "        }\n",
    "        \n",
    "        dev_df = pd.read_csv(\"/kaggle/input/code-injection/dataset_capec_\" + dataset + \".csv\")\n",
    "        data_size = dev_df.shape[0]\n",
    "        selected_for_evaluation = int(data_size*percentage/100)\n",
    "        dev_df = dev_df.head(selected_for_evaluation)\n",
    "        dataset = ReviewDataset(dev_df)\n",
    "\n",
    "        dataloader = DataLoader(dataset = dataset, batch_size = training_parameters[\"batch_size\"], shuffle = True, num_workers = 2)\n",
    "\n",
    "        mean_accuracy = 0.0\n",
    "        total_batches = len(dataloader)\n",
    "        \n",
    "        true_labels = list()\n",
    "        predicted_label = list()\n",
    "        \n",
    "        for input_ids, attention_mask, token_type_ids, labels in dataloader:\n",
    "            inputs = {\n",
    "                \"input_ids\": input_ids.squeeze(axis=1),\n",
    "                \"attention_mask\": attention_mask.squeeze(axis=1),\n",
    "                \"token_type_ids\" : token_type_ids.squeeze(axis=1),\n",
    "                \"labels\": labels,\n",
    "            }\n",
    "            for k, v in inputs.items():\n",
    "                inputs[k] = v.to(device)\n",
    "            attack_pred, _ = model(**inputs)\n",
    "            true_labels.extend(attack_pred.max(dim = 1)[1].cpu().numpy())\n",
    "            predicted_label.extend(inputs['labels'].cpu().numpy())\n",
    "            _, predicted_labels = compute_accuracy(attack_pred, inputs[\"labels\"])\n",
    "\n",
    "\n",
    "            sentiment_pred, _ = model(**inputs)\n",
    "            accuracy, predicted_labels = compute_accuracy(sentiment_pred, inputs[\"labels\"])\n",
    "            mean_accuracy += accuracy\n",
    "            for i in range(7): \n",
    "                predicted_labels_dict[i] += predicted_labels[i]\n",
    "        score = f1_score(true_labels,predicted_label,average=\"macro\")\n",
    "        precision = precision_score(true_labels, predicted_label,average=\"macro\")\n",
    "        recall = recall_score(true_labels, predicted_label,average=\"macro\")\n",
    "        report = classification_report(true_labels,predicted_label,digits=4)\n",
    "        acc= accuracy_score(true_labels, predicted_label)\n",
    "        #classifaction_report_csv(report,precision,recall,score,0)\n",
    "        print ('\\n clasification report:\\n', report)\n",
    "        print ('F1 score:', score)\n",
    "        print ('Recall:', recall)\n",
    "        print ('Precision:', precision)\n",
    "        print ('Acc:', acc)\n",
    "        print('Confusion Matrix: \\n',confusion_matrix(true_labels, predicted_label))\n",
    "        print(predicted_labels_dict)\n",
    "#     return mean_accuracy/total_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "253d3172",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T07:37:16.449672Z",
     "iopub.status.busy": "2023-08-14T07:37:16.449368Z",
     "iopub.status.idle": "2023-08-14T08:05:35.321714Z",
     "shell.execute_reply": "2023-08-14T08:05:35.320450Z"
    },
    "papermill": {
     "duration": 1698.89846,
     "end_time": "2023-08-14T08:05:35.338483",
     "exception": false,
     "start_time": "2023-08-14T07:37:16.440023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at jackaduma/SecBERT were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 0\n",
      "Training Step: 100\n",
      "Training Step: 200\n",
      "Training Step: 300\n",
      "Training Step: 400\n",
      "Training Step: 500\n",
      "Training Step: 600\n",
      "Training Step: 700\n",
      "Training Step: 800\n",
      "Training Step: 900\n",
      "Training Step: 1000\n",
      "Training Step: 1100\n",
      "Training Step: 1200\n",
      "Training Step: 1300\n",
      "Training Step: 1400\n",
      "Training Step: 1500\n",
      "Training Step: 1600\n",
      "Training Step: 1700\n",
      "Training Step: 1800\n",
      "Training Step: 1900\n",
      "Training Step: 2000\n",
      "Training Step: 2100\n",
      "Training Step: 2200\n",
      "Training Step: 2300\n",
      "Training Step: 2400\n",
      "Training Step: 2500\n",
      "Training Step: 2600\n",
      "Training Step: 2700\n",
      "Training Step: 2800\n",
      "Training Step: 2900\n",
      "Training Step: 3000\n",
      "Training Step: 3100\n",
      "Training Step: 3200\n",
      "Training Step: 3300\n",
      "Training Step: 3400\n",
      "Training Step: 3500\n",
      "Training Step: 3600\n",
      "Training Step: 3700\n",
      "Training Step: 3800\n",
      "Training Step: 3900\n",
      "Training Step: 4000\n",
      "Training Step: 4100\n",
      "Training Step: 4200\n",
      "Training Step: 4300\n",
      "Training Step: 4400\n",
      "Training Step: 4500\n",
      "Training Step: 4600\n",
      "Training Step: 4700\n",
      "Training Step: 4800\n",
      "Training Step: 4900\n",
      "Training Step: 5000\n",
      "Training Step: 5100\n",
      "Training Step: 5200\n",
      "Training Step: 5300\n",
      "Training Step: 5400\n",
      "Training Step: 5500\n",
      "Training Step: 5600\n",
      "Training Step: 5700\n",
      "Training Step: 5800\n",
      "Training Step: 5900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      5159\n",
      "           1     0.2275    0.0716    0.1089       531\n",
      "           2     0.4824    0.9190    0.6327      4813\n",
      "           3     0.0051    1.0000    0.0102        10\n",
      "           4     0.0000    0.0000    0.0000        36\n",
      "           5     0.0000    0.0000    0.0000       456\n",
      "           6     0.8970    0.5885    0.7107       814\n",
      "\n",
      "    accuracy                         0.4188     11819\n",
      "   macro avg     0.2303    0.3684    0.2089     11819\n",
      "weighted avg     0.2685    0.4188    0.3115     11819\n",
      "\n",
      "F1 score: 0.20892641776125553\n",
      "Recall: 0.36842637638328685\n",
      "Precision: 0.23030225408596644\n",
      "Acc: 0.41881715881208226\n",
      "Confusion Matrix: \n",
      " [[   0   81 4037 1011    0    0   30]\n",
      " [   0   38  393  100    0    0    0]\n",
      " [   0   47 4423  318    0    0   25]\n",
      " [   0    0    0   10    0    0    0]\n",
      " [   0    1    0   35    0    0    0]\n",
      " [   0    0    0  456    0    0    0]\n",
      " [   0    0  315   20    0    0  479]]\n",
      "{0: 5159, 1: 532, 2: 4806, 3: 12, 4: 35, 5: 454, 6: 821}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "lr = training_parameters[\"learning_rate\"]\n",
    "n_epochs = training_parameters[\"epochs\"]\n",
    "\n",
    "model = DomainAdaptationModel()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr)\n",
    "\n",
    "loss_fn_sentiment_classifier = torch.nn.NLLLoss()\n",
    "loss_fn_domain_classifier = torch.nn.NLLLoss()\n",
    "'''\n",
    "In one training step we will update the model using both the source labeled data and target unlabeled data\n",
    "We will run it till the batches last for any of these datasets\n",
    "\n",
    "In our case target dataset has more data. Hence, we will leverage the entire source dataset for training\n",
    "\n",
    "If we use the same approach in a case where the source dataset has more data then the target dataset then we will\n",
    "under-utilize the labeled source dataset. In such a scenario it is better to reload the target dataset when it finishes\n",
    "This will ensure that we are utilizing the entire source dataset to train our model.\n",
    "'''\n",
    "\n",
    "max_batches = min(len(source_dataloader), len(target_dataloader))\n",
    "\n",
    "for epoch_idx in range(n_epochs):\n",
    "    \n",
    "    source_iterator = iter(source_dataloader)\n",
    "    target_iterator = iter(target_dataloader)\n",
    "\n",
    "    for batch_idx in range(max_batches):\n",
    "        \n",
    "        p = float(batch_idx + epoch_idx * max_batches) / (training_parameters[\"epochs\"] * max_batches)\n",
    "        grl_lambda = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "        grl_lambda = torch.tensor(grl_lambda)\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        if(batch_idx%training_parameters[\"print_after_steps\"] == 0 ):\n",
    "            print(\"Training Step:\", batch_idx)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Souce dataset training update\n",
    "        input_ids, attention_mask, token_type_ids, labels = next(source_iterator)\n",
    "        inputs = {\n",
    "            \"input_ids\": input_ids.squeeze(axis=1),\n",
    "            \"attention_mask\": attention_mask.squeeze(axis=1),\n",
    "            \"token_type_ids\" : token_type_ids.squeeze(axis=1),\n",
    "            \"labels\" : labels,\n",
    "            \"grl_lambda\" : grl_lambda,\n",
    "        }\n",
    "\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "    \n",
    "        sentiment_pred, domain_pred = model(**inputs)\n",
    "        loss_s_sentiment = loss_fn_sentiment_classifier(sentiment_pred, inputs[\"labels\"])\n",
    "        y_s_domain = torch.zeros(training_parameters[\"batch_size\"], dtype=torch.long).to(device)\n",
    "        loss_s_domain = loss_fn_domain_classifier(domain_pred, y_s_domain)\n",
    "\n",
    "\n",
    "        # Target dataset training update \n",
    "        input_ids, attention_mask, token_type_ids, labels = next(target_iterator)\n",
    "        inputs = {\n",
    "            \"input_ids\": input_ids.squeeze(axis=1),\n",
    "            \"attention_mask\": attention_mask.squeeze(axis=1),\n",
    "            \"token_type_ids\" : token_type_ids.squeeze(axis=1),\n",
    "            \"labels\" : labels,\n",
    "            \"grl_lambda\" : grl_lambda,\n",
    "        }\n",
    "\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "    \n",
    "        _, domain_pred = model(**inputs)\n",
    "        \n",
    "        # Note that we are not using the sentiment predictions here for updating the weights\n",
    "        y_t_domain = torch.ones(input_ids.shape[0], dtype=torch.long).to(device)\n",
    "        # print(domain_pred.shape, y_t_domain.shape)\n",
    "        loss_t_domain = loss_fn_domain_classifier(domain_pred, y_t_domain)\n",
    "\n",
    "        # Combining the loss \n",
    "\n",
    "        loss = loss_s_sentiment + loss_s_domain + loss_t_domain\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluate the model after every epoch\n",
    "    \n",
    "    torch.save(model.state_dict(), os.path.join(training_parameters[\"output_folder\"], \"epoch_\" + str(epoch_idx)  +  training_parameters[\"output_file\"] ))\n",
    "#     accuracy = evaluate(model, dataset = \"combine\", percentage = 1).item()\n",
    "#     print(\"Accuracy on amazon after epoch \" + str(epoch_idx) + \" is \" + str(accuracy))\n",
    "\n",
    "    accuracy = evaluate(model, dataset = \"transfer\", percentage = 100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fcf9fdf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-14T08:05:35.367167Z",
     "iopub.status.busy": "2023-08-14T08:05:35.366840Z",
     "iopub.status.idle": "2023-08-14T08:12:41.027985Z",
     "shell.execute_reply": "2023-08-14T08:12:41.026770Z"
    },
    "papermill": {
     "duration": 425.693085,
     "end_time": "2023-08-14T08:12:41.044898",
     "exception": false,
     "start_time": "2023-08-14T08:05:35.351813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      5163\n",
      "           1     0.2216    0.0690    0.1053       536\n",
      "           2     0.4828    0.9221    0.6337      4800\n",
      "           3     0.0031    1.0000    0.0061         6\n",
      "           4     0.0000    0.0000    0.0000        37\n",
      "           5     0.0000    0.0000    0.0000       455\n",
      "           6     0.9007    0.5852    0.7094       822\n",
      "\n",
      "    accuracy                         0.4188     11819\n",
      "   macro avg     0.2297    0.3680    0.2078     11819\n",
      "weighted avg     0.2688    0.4188    0.3115     11819\n",
      "\n",
      "F1 score: 0.2077959864224457\n",
      "Recall: 0.3680387621330262\n",
      "Precision: 0.2297355737259053\n",
      "Acc: 0.41881715881208226\n",
      "Confusion Matrix: \n",
      " [[   0   84 4029 1018    0    0   32]\n",
      " [   0   37  392  107    0    0    0]\n",
      " [   0   44 4426  309    0    0   21]\n",
      " [   0    0    0    6    0    0    0]\n",
      " [   0    2    0   35    0    0    0]\n",
      " [   0    0    0  455    0    0    0]\n",
      " [   0    0  321   20    0    0  481]]\n",
      "{0: 5196, 1: 532, 2: 4784, 3: 7, 4: 34, 5: 453, 6: 813}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluate(model, dataset = \"transfer\", percentage = 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2191.505512,
   "end_time": "2023-08-14T08:12:43.896114",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-14T07:36:12.390602",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03621d45728e4c7b83492911cc2b1539": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "061b6d13a539441299e388e954030230": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4c4f658a817d42d592001961369e5c15",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_06282efa1a02435aa0f4058de2637a52",
       "value": "Downloading (â€¦)lve/main/config.json: 100%"
      }
     },
     "06282efa1a02435aa0f4058de2637a52": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "0e421f07704c4a97bbec0f9facf63e06": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e3c1d07028fd4ff1ba3791259ea8ce24",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_893a810a34bd4aab9f7e7c73c772ed88",
       "value": " 336M/336M [00:03&lt;00:00, 108MB/s]"
      }
     },
     "1a13c73a88f54628ac2eae703c52066a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_03621d45728e4c7b83492911cc2b1539",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_e2aa94cd8ce748c5a840f0589cc4956e",
       "value": " 378k/378k [00:00&lt;00:00, 5.17MB/s]"
      }
     },
     "1ffaeb669e8d4dfeb597a5100facfd94": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6e90c99f75f9494d96bd51728d547778",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_3a491e5b43fd4f6aa8eba2119e2511fd",
       "value": "Downloading (â€¦)solve/main/vocab.txt: 100%"
      }
     },
     "29bc3df5c6474c2c9588b03245629d18": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3a491e5b43fd4f6aa8eba2119e2511fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "405e94d6229e4a05863d5fff6880c43f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7ffd4598f36d4708814f12b9173388af",
       "max": 378000.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_29bc3df5c6474c2c9588b03245629d18",
       "value": 378000.0
      }
     },
     "46ec59805e034f56a5fbff2a63d415d7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4c4f658a817d42d592001961369e5c15": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4fb94101eaad4010b968314b39c4b6bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_061b6d13a539441299e388e954030230",
        "IPY_MODEL_84ffe4d71d574138a472062d6add188d",
        "IPY_MODEL_6e69bce1774644a4a75598ab38b7c45e"
       ],
       "layout": "IPY_MODEL_7f504ce5e9224a7793fb3983543ec4b3"
      }
     },
     "537434bacef541918c700138745c060c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "53e448a1a0864a19ababb6af0002d43d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f4ad80a204534eff9fe587b4c6c3ffa8",
       "max": 336396808.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5fc8a003009f47d5aafddccaa870e164",
       "value": 336396808.0
      }
     },
     "5eae422271f6472a99088d49fc409f2b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5fc8a003009f47d5aafddccaa870e164": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "61f213c11ad0480a83b2678cb907b598": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "67407e0855f54a258c021dfaa9acde71": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "68bfd973f1cb40aea4a4f0e8306be356": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6e69bce1774644a4a75598ab38b7c45e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c2735dcb07a545ba983e5cfe53120aa4",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_61f213c11ad0480a83b2678cb907b598",
       "value": " 467/467 [00:00&lt;00:00, 32.4kB/s]"
      }
     },
     "6e90c99f75f9494d96bd51728d547778": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "76963a26d91f4edaa2c5b54fe4e5989f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1ffaeb669e8d4dfeb597a5100facfd94",
        "IPY_MODEL_405e94d6229e4a05863d5fff6880c43f",
        "IPY_MODEL_1a13c73a88f54628ac2eae703c52066a"
       ],
       "layout": "IPY_MODEL_46ec59805e034f56a5fbff2a63d415d7"
      }
     },
     "7f504ce5e9224a7793fb3983543ec4b3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7ffd4598f36d4708814f12b9173388af": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "84ffe4d71d574138a472062d6add188d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_68bfd973f1cb40aea4a4f0e8306be356",
       "max": 467.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_537434bacef541918c700138745c060c",
       "value": 467.0
      }
     },
     "893a810a34bd4aab9f7e7c73c772ed88": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "94243ae49bed433e90d1f2f2ae1f6301": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ace8c72f223c42be89bacfc2d258b821",
        "IPY_MODEL_53e448a1a0864a19ababb6af0002d43d",
        "IPY_MODEL_0e421f07704c4a97bbec0f9facf63e06"
       ],
       "layout": "IPY_MODEL_f51cb37d601d4fa6910dd4f36547e994"
      }
     },
     "ace8c72f223c42be89bacfc2d258b821": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_67407e0855f54a258c021dfaa9acde71",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_5eae422271f6472a99088d49fc409f2b",
       "value": "Downloading model.safetensors: 100%"
      }
     },
     "c2735dcb07a545ba983e5cfe53120aa4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e2aa94cd8ce748c5a840f0589cc4956e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e3c1d07028fd4ff1ba3791259ea8ce24": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f4ad80a204534eff9fe587b4c6c3ffa8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f51cb37d601d4fa6910dd4f36547e994": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
